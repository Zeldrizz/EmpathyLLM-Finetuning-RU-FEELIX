# Используемые модели и датасеты

## Модели

1. **Llama 3.2 1B Instruct RU**  
   Дообученная на русскоязычном датасете.  
   [Ссылка на модель](https://huggingface.co/Vikhrmodels/Vikhr-Llama-3.2-1B-Instruct)

2. **Llama 3.1 8B Instruct RU**  
   Дообученная на русскоязычном датасете.  
   [Ссылка на модель](https://huggingface.co/Vikhrmodels/Vikhr-Llama3.1-8B-Instruct-R-21-09-24)

3. **T-lite-it-1.0**  
   LLM семейства qwen2, 7.6b ~ 8b параметров, дообученная Т-банковцами для генерации текста на русском языке.  
   [Ссылка на модель](https://huggingface.co/t-tech/T-lite-it-1.0)

---

## Датасеты

1. **forum**  
   Русскоязычный датасет, полученный самостоятельным парсингом психологических форумов (~2000 строк).  
   Формат: `вопрос1 - ответ1`, `вопрос1 - ответ2`, `вопрос2 - ответ1` и т.д.  
   Обработка:
   - Удалены вопросы и ответы с низкой репутацией или короткой длиной.
   - Удалены специфичные для форумов приписки к пользователям, например:  
     `Елена ответил(а) Александру:`, `Елена ответил(а) через 5 минут:`.

2. **forum-gpt**  
   Объединение датасета `forum` с самостоятельно сгенерированными вопросами и ответами GPT-4o психологического характера (~2500–3000 строк).  

3. **STCD**  
   Датасет с Kaggle: [Synthetic Therapy Conversations Dataset](https://www.kaggle.com/datasets/thedevastator/synthetic-therapy-conversations-dataset).  
   Особенности:
   - Содержит диалоги человека с ChatGPT с фокусом на улучшение психологического состояния.  
   - Размер (~8000 строк).
   - Обработка:
     - Удалены имена.
     - Перевод из json в текстовый формат с добавлением тегов <USER> и <ASSISTANT>
     - Переведен на русский язык с использованием `googletrans` (около 8 часов работы скрипта).  

4. **STCD-big-ver1**  
   Расширенная версия STCD (>22,000 строк).  

5. **STCD-GMPM**  
   Объединение:
   - ~11,000 строк из `STCD-big-ver1`.
   - ~5000 строк из [Grand Master Pro Max](https://huggingface.co/datasets/Vikhrmodels/GrandMaster-PRO-MAX), инструктивного датасета, сгенерированного LLM. Выбирал именно те строки, у которых менее 1024 токенов в вопросах и ответах, и в которых встречаются ключевые слова "психология", "учеба", "университет", "стресс" и тд.

6. **STCD-GMPM_S**  
   Объединение:
   - ~18,000 строк из `STCD-big-ver1` на train.
      - ~2,000 из `STCD-big-ver1` строк на valid
      - ~2,000 из `STCD-big-ver1` строк на test
      - train + test + valid - в сумме дают весь датасет STCD-big-ver1 и между собой не пересекаются.
   - ~2000 строк из [Grand Master Pro Max](https://huggingface.co/datasets/Vikhrmodels/GrandMaster-PRO-MAX), инструктивного датасета, сгенерированного LLM. Выбирал именно те строки, у которых менее 1024 токенов в вопросах и ответах, и в которых встречаются ключевые слова "психология", "учеба", "университет", "стресс" и тд.

7. **STCD-GMPM_T-PSYCH**  
   Объединение:
   - ~18,000 строк из `STCD-big-ver1` на train.
      - ~2,000 из `STCD-big-ver1` строк на valid
      - ~2,000 из `STCD-big-ver1` строк на test
      - train + test + valid - в сумме дают весь датасет STCD-big-ver1 и между собой не пересекаются.
   - ~700 строк из [Grand Master Pro Max](https://huggingface.co/datasets/Vikhrmodels/GrandMaster-PRO-MAX), инструктивного датасета, сгенерированного LLM. Выбирал именно те строки, у которых менее 1024 токенов в вопросах и ответах, и в которых встречаются ключевые слова "психология", "учеба", "университет", "стресс" и тд.
   - ~2400 строк было спарсено с психологического форума, где пользователи задавали вопросы под профилями опытных и практикующих психологов, а те им отвечали. Этот датасет схож с датасетом "forum": также использовался парсинг веб-страниц и проводилась аналогичная очистка данных. Имена были удалены с помощью natasha, но в отличие от "forum", ответы здесь давали не обычные участники форума, а профессиональные психологи.

8. **STCD-PSYCH**  
   Объединение:
   - ~18,000 строк из `STCD-big-ver1` на train.
      - ~2,000 из `STCD-big-ver1` строк на valid
      - ~2,000 из `STCD-big-ver1` строк на test
      - train + test + valid - в сумме дают весь датасет STCD-big-ver1 и между собой не пересекаются.
   - ~2400 строк было спарсено с психологического форума, где пользователи задавали вопросы под профилями опытных и практикующих психологов, а те им отвечали. Этот датасет схож с датасетом "forum": также использовался парсинг веб-страниц и проводилась аналогичная очистка данных. Имена были удалены с помощью natasha, но в отличие от "forum", ответы здесь давали не обычные участники форума, а профессиональные психологи.

9. **STCD-PSYCH-COMBINED**  
   Как это было:
   - 1 этап) взял STCD-big-ver1 (>22,000 строк) поделил его следующим образом: train 81% от STCD-big-ver1, test 10% от STCD-big-ver1 и valid 9% от STCD-big-ver1. Между собойб train, test и valid не пересекаются.
   - 2 этап) точно такое же деление проделал с ответами психологов с одного психологического форума, где всего около 2400 строк.
   - 3 этап) объединил train с STCD-big-ver1 и train c ответами психологов с одного психологического форума, тоже самое проделал с test и valid. В итоге train, valid, test присутсвуют как синтетические эмпатичные ответы, так и психологическая консультация/помощь от реальных людей психологов.

   - Собственно, LLM получается на полученном train, веса корректируются на полученной valid, и итоговая проверка на test.
---

## Структура проекта

- **test_base_models**  
  Ответы моделей до обучения (finetune).

- **datasets_preview**  
  Первые 25 случайных строк из используемых датасетов.  
  _Полные версии датасетов не размещены из-за ограничений GitHub на размер файлов._

- **Папки моделей после обучения**  
  Пример: `llama-3.2-1b-ep5-STCD`  
  Финальная версия модели после обучения (finetune) на датасете STCD за 5 эпох.  
  Содержимое папки:
  - `main.py` — код запуска обучения.
  - `.sh` скрипты — для запуска на кластере.
  - `total_statistics.png` — результаты обучения (графики train loss, eval loss и т.д.).
  - `responses.txt` — ответы модели на вопросы после обучения.

---
